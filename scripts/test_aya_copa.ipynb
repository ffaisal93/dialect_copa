{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b934a4-3c64-4c16-8849-455ce939d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import logging\n",
    "from generate_utility import *\n",
    "from utility import *\n",
    "from transformers.generation import GenerationConfig\n",
    "from peft import PeftModel\n",
    "# import bitsandbytes as bnb\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed063140-0f8e-4f57-9f0c-52d59b9bdf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards:  73%|███████▎  | 8/11 [01:37<00:36, 12.20s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 39.25 GiB total capacity; 38.88 GiB already allocated; 63.88 MiB free; 38.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m config \u001b[38;5;241m=\u001b[39m PeftConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(peft_model_id)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# load base LLM model and tokenizer\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(config\u001b[38;5;241m.\u001b[39mbase_model_name_or_path)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Load the Lora model\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:565\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    564\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m )\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/transformers/modeling_utils.py:3307\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3298\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3300\u001b[0m     (\n\u001b[1;32m   3301\u001b[0m         model,\n\u001b[1;32m   3302\u001b[0m         missing_keys,\n\u001b[1;32m   3303\u001b[0m         unexpected_keys,\n\u001b[1;32m   3304\u001b[0m         mismatched_keys,\n\u001b[1;32m   3305\u001b[0m         offload_index,\n\u001b[1;32m   3306\u001b[0m         error_msgs,\n\u001b[0;32m-> 3307\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3314\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3315\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3318\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3319\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3325\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   3326\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/transformers/modeling_utils.py:3695\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m low_cpu_mem_usage:\n\u001b[1;32m   3694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_fsdp_enabled_and_dist_rank_0():\n\u001b[0;32m-> 3695\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3702\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3703\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3706\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_quantized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3709\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3710\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3711\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   3712\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/transformers/modeling_utils.py:741\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, is_quantized, is_safetensors, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m    738\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate`\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mint8 \u001b[38;5;129;01mand\u001b[39;00m param_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/accelerate/utils/modeling.py:384\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    382\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 384\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 39.25 GiB total capacity; 38.88 GiB already allocated; 63.88 MiB free; 38.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load peft config for pre-trained checkpoint etc.\n",
    "peft_model_id = \"temp\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path,   device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc479d6-d044-43a2-ae1b-0eeb341f5cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 11/11 [00:56<00:00,  5.17s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"../models/aya-101\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "873811a5-9c97-44c3-9159-cbb05490bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_result(prompts,gen_config,model_name='aya',bs=8):\n",
    "    all_response=[]\n",
    "    all_response_raw=[]\n",
    "    end=len(prompts)\n",
    "    for start in tqdm(range(0,end,bs)):\n",
    "        stop=min(start+bs,len(prompts))\n",
    "        if start<stop:\n",
    "            prompts_batch=prompts[start:stop]\n",
    "            encodings=tokenizer(prompts_batch, return_tensors=\"pt\", padding='longest', truncation=False).to(\"cuda\")\n",
    "            with torch.no_grad():\n",
    "                output_ids = model.generate(**encodings, **gen_config)\n",
    "            responses=tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "            for i,response_raw in enumerate(responses):\n",
    "                sample_no=i+start\n",
    "                if model_name!='aya':\n",
    "                    response=response_raw[len(prompts[sample_no]):]\n",
    "                    response=response.split(\"\\n\")[0].strip() if \"\\n\" in response else response.strip()\n",
    "                else:\n",
    "                    response=response_raw[-1]\n",
    "                all_response.append(response)\n",
    "                all_response_raw.append(response_raw)\n",
    "                \n",
    "    return all_response_raw,all_response\n",
    "\n",
    "def eval_result(all_preds,all_true_labels):\n",
    "    count=0\n",
    "    ind_true=[]\n",
    "    not_true=[]\n",
    "    indx=[]\n",
    "    for i,res in enumerate(all_preds):\n",
    "        if res in choices:\n",
    "            if choices.index(res)==all_true_labels[i]:\n",
    "                count+=1\n",
    "                ind_true.append(i)\n",
    "            else:\n",
    "                not_true.append(i)\n",
    "                indx.append(res)\n",
    "    acc=count/len(all_preds)\n",
    "    # print(acc, count, len(all_preds), len(all_true_labels), not_true,indx)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e974e844-2bd5-43fc-a45b-d25b2f3d39ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_few_shot_examples(dataset, question,fs_per_label=2, seed=42):\n",
    "    labels = list(set(dataset[\"label\"]))\n",
    "    few_shot_examples = []\n",
    "    for label in labels:\n",
    "        label_examples = dataset.filter(lambda example: example[\"label\"] == label and example[\"question\"]==question)\n",
    "        # shuffle the examples\n",
    "        label_examples = label_examples.shuffle(seed=seed)\n",
    "        # get the first fs_per_label examples\n",
    "        label_examples = label_examples.select(\n",
    "            range(min(fs_per_label, len(label_examples)))\n",
    "        )\n",
    "        few_shot_examples += [example for example in label_examples]\n",
    "\n",
    "    # Shuffle the few shot examples\n",
    "    random.shuffle(few_shot_examples)\n",
    "    return few_shot_examples\n",
    "\n",
    "def test_construct_Prompt(ds_examples,min_ex=4):\n",
    "    ds_examples=ds_examples[:min_ex]\n",
    "    prompt_examples = \"\\n\\n\".join([ prompt_template_cause.format(**d,correct_answer=choices[int(d[\"label\"])]) \n",
    "                                   if d[\"question\"]=='cause' \n",
    "                                   else prompt_template_effect.format(**d,correct_answer=choices[int(d[\"label\"])])\n",
    "                                   for d in ds_examples])\n",
    "    prompt_examples=preamble+\"\\n\\n\\n\"+prompt_examples\n",
    "    return prompt_examples\n",
    "\n",
    "def construct_single(row,fs_prompt):\n",
    "    if row['question']=='cause':\n",
    "        prompt=(fs_prompt + \"\\n\\n\" + prompt_template_cause.format(**row, correct_answer=\"\")).strip()\n",
    "        # prompt=(prompt_template_cause.format(**row, correct_answer=\"\")).strip()\n",
    "    else:\n",
    "        prompt=(fs_prompt + \"\\n\\n\" + prompt_template_effect.format(**row, correct_answer=\"\")).strip()\n",
    "        # prompt=( prompt_template_cause.format(**row, correct_answer=\"\")).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3242890-5c05-400d-a482-592a13857576",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_config = {\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.1,\n",
    "                \"repetition_penalty\": 1.18,\n",
    "                \"top_k\": 40,\n",
    "                \"do_sample\": True,\n",
    "                \"max_new_tokens\": 5,\n",
    "                \"pad_token_id\": tokenizer.eos_token_id\n",
    "                    }\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a44f2221-1c37-46df-9186-3d88d74b9147",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/copa-ck/train.trans.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m=\u001b[39m\u001b[43mload_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcopa-ck\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/scripts/utility.py:79\u001b[0m, in \u001b[0;36mload_datasets\u001b[0;34m(lang, DATADIR)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     78\u001b[0m     path\u001b[38;5;241m=\u001b[39mPath(DATADIR,lang,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.trans.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     80\u001b[0m     lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m     81\u001b[0m line_dicts \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/copa-ck/train.trans.jsonl'"
     ]
    }
   ],
   "source": [
    "dataset=dataset=load_datasets('copa-ck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbac1af5-1041-4507-a132-4e3f96b3d7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'Moje telo je pravilo senku na travi.',\n",
       " 'choice1': 'Sunce je izlazilo.',\n",
       " 'choice2': 'Trava je bila pokošena.',\n",
       " 'question': 'cause',\n",
       " 'label': 0,\n",
       " 'idx': 0,\n",
       " 'changed': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6fe2dbb-c66a-4db7-9e6c-e9ca60cd577e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 400\n",
      "val size: 100\n",
      "{'premise': 'The man turned on the faucet.', 'choice1': 'The toilet filled with water.', 'choice2': 'Water flowed from the spout.', 'question': 'effect', 'label': 1, 'idx': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 279.23ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 294.67ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 288.90ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 293.70ba/s]\n",
      "100%|██████████| 13/13 [00:22<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 400\n",
      "val size: 100\n",
      "{'premise': 'Muškarac je otvorio slavinu.', 'choice1': 'Zahodska se školjka napunila vodom.', 'choice2': 'Voda je potekla iz mlaznice.', 'question': 'effect', 'label': 1, 'idx': 0, 'changed': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 250.21ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 263.63ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 263.99ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 265.45ba/s]\n",
      "100%|██████████| 13/13 [00:24<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 400\n",
      "val size: 100\n",
      "{'choice1': 'Stranišče se je napolnilo z vodo.', 'choice2': 'Iz ustja pipe je pritekla voda.', 'idx': 0, 'label': 1, 'premise': 'Moški je odprl pipo.', 'question': 'effect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 250.57ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 275.63ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 274.86ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 260.73ba/s]\n",
      "100%|██████████| 13/13 [00:23<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 400\n",
      "val size: 100\n",
      "{'choice1': 'Skrit se je napauhnu z uoda.', 'choice2': 'Iz pipe je partjekla uoda.', 'idx': 0, 'label': 1, 'premise': 'Dic je adparu pipa.', 'question': 'effect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 276.50ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 286.77ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 291.64ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 288.68ba/s]\n",
      "100%|██████████| 13/13 [00:24<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 400\n",
      "val size: 100\n",
      "{'premise': 'Човек је отворио славину.', 'choice1': 'WC шоља се напунила водом.', 'choice2': 'Вода је текла из славине.', 'question': 'effect', 'label': 1, 'idx': 0, 'changed': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 238.96ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 260.22ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 254.37ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 259.50ba/s]\n",
      "100%|██████████| 13/13 [00:24<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 400\n",
      "val size: 100\n",
      "{'premise': 'Човек одврнуја славину.', 'choice1': 'Ве-це се напунија сас воду.', 'choice2': 'Вода истичала од славину.', 'question': 'effect', 'label': 1, 'idx': 0, 'changed': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 245.07ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 253.85ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 258.94ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 269.45ba/s]\n",
      "100%|██████████| 13/13 [00:23<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 400\n",
      "val size: 100\n",
      "{'premise': 'Човекот ја отвори славината.', 'choice1': 'Tоалетот се наполни со вода.', 'choice2': 'Истече вода од славината.', 'question': 'effect', 'label': 1, 'idx': 0, 'changed': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 239.61ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 258.91ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 260.22ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 244.42ba/s]\n",
      "100%|██████████| 13/13 [00:24<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 400\n",
      "val size: 100\n",
      "{'premise': 'Muškarac je otvorio slavinu.', 'choice1': 'Zahodska sve školjka napunila vodom.', 'choice2': 'Voda je potekla iz mlaznice.', 'question': 'effect', 'idx': 0, 'label': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 266.25ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 277.33ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 287.42ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 287.44ba/s]\n",
      "100%|██████████| 13/13 [00:25<00:00,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "all_lang_data={\n",
    "    'english':'copa-en',\n",
    "    'croatian':'copa-hr',\n",
    "    'Slovenian':'copa-sl',\n",
    "    'Cerkno-dialect-of-Slovenian':'copa-sl-cer',\n",
    "    'Serbian':'copa-sr',\n",
    "    'Torlak-dialect':'copa-sr-tor',\n",
    "    'Macedonian':'copa-mk' \n",
    "}\n",
    "\n",
    "all_results=[]\n",
    "eval_type='val'\n",
    "for lang,dfile in all_lang_data.items():\n",
    "\n",
    "    choices=[\"A\",\"B\"]\n",
    "    \n",
    "    preamble = f\"\"\"You are a helpful assistant whose goal is to select the correct output for a given instruction in {lang}.\"\"\"\n",
    "\n",
    "    prompt_template_cause=\"\"\"Instruction: Given the premise, \"\"{premise}\"\", What is the correct {question} before this?\n",
    "    A: {choice1}\n",
    "    B: {choice2}\n",
    "    Correct {question}: {correct_answer}\"\"\"\n",
    "\n",
    "    prompt_template_effect=\"\"\"Instruction: Given the premise, \"\"{premise}\"\", What is the correct {question} after this?\n",
    "    A: {choice1}\n",
    "    B: {choice2}\n",
    "    Correct {question}: {correct_answer}\"\"\"\n",
    "    \n",
    "    dataset=dataset=load_datasets(dfile)\n",
    "    \n",
    "    print(dataset['val'][0])\n",
    "    \n",
    "    all_val_prompts=[]\n",
    "    all_val_labels=[]\n",
    "    fs_examp_cause=get_few_shot_examples(dataset['train'],'cause',fs_per_label=2,seed=41)\n",
    "    fs_examp_effect=get_few_shot_examples(dataset['train'],'effect',fs_per_label=2,seed=42)\n",
    "    fs_prompt_cause=test_construct_Prompt(fs_examp_cause)\n",
    "    fs_prompt_effect=test_construct_Prompt(fs_examp_effect)\n",
    "    for row in dataset['val']:\n",
    "        if row['question']=='effect':\n",
    "            prompt=(fs_prompt_effect + \"\\n\\n\" + prompt_template.format(**row, correct_answer=\"\")).strip()\n",
    "        else:\n",
    "            prompt=(fs_prompt_cause + \"\\n\\n\" + prompt_template.format(**row, correct_answer=\"\")).strip()\n",
    "        all_val_prompts.append(prompt)\n",
    "        all_val_labels.append(row['label'])\n",
    "        \n",
    "    all_response_raw,all_response=generate_result(all_val_prompts,gen_config,'aya')\n",
    "    \n",
    "    acc=eval_result(all_response,all_val_labels)\n",
    "    res={\n",
    "        'name':f'{eval_type}-{dfile}',\n",
    "        'test_accuracy': acc,\n",
    "        'test_loss': 0,\n",
    "        'test_runtime': 0,\n",
    "        'test_samples_per_second': 0,\n",
    "        'test_steps_per_second': 0\n",
    "    }\n",
    "    all_results.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dcf271d6-0fb0-43e0-b95c-34b5d38ef759",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(f\"../results/{eval_type}_aya.txt\", \"w\")\n",
    "for k in all_results:\n",
    "    for vk,vv in k.items():\n",
    "        if vk=='name':\n",
    "            output.writelines(f'{vv}\\n')\n",
    "        else:\n",
    "            output.writelines(f'{vk} = {vv:.4f}\\n')\n",
    "    output.writelines(f'\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3642347-4380-4b99-a0aa-75e4473df005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "my_file = Path(\"dd\",\"dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62aff94b-6d92-4bed-b60b-589a043240b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('dd/dd')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4ef5a-2430-47a6-bf4d-51af142f2f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
