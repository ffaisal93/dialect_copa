{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d1b546-d069-43b3-871a-6180410514ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 24845\n",
      "Validation dataset size: 8\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,load_from_disk\n",
    "\n",
    "# Load dataset from the hub\n",
    "train_dataset = load_from_disk(\"../data/orgl\")\n",
    "val_dataset = load_from_disk(\"../data/all_val\")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset['train'])}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19671095-7ecb-487d-bb6d-f29126d39bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    copa-ck: Dataset({\n",
       "        features: ['premise', 'choice1', 'choice2', 'question', 'idx', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    copa-en: Dataset({\n",
       "        features: ['premise', 'choice1', 'choice2', 'question', 'label', 'idx'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    copa-hr: Dataset({\n",
       "        features: ['premise', 'choice1', 'choice2', 'question', 'label', 'idx', 'changed'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    copa-mk: Dataset({\n",
       "        features: ['premise', 'choice1', 'choice2', 'question', 'label', 'idx', 'changed'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    copa-sl: Dataset({\n",
       "        features: ['choice1', 'choice2', 'idx', 'label', 'premise', 'question'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    copa-sl-cer: Dataset({\n",
       "        features: ['choice1', 'choice2', 'idx', 'label', 'premise', 'question'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    copa-sr: Dataset({\n",
       "        features: ['premise', 'choice1', 'choice2', 'question', 'label', 'idx', 'changed'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    copa-sr-tor: Dataset({\n",
       "        features: ['premise', 'choice1', 'choice2', 'question', 'label', 'idx', 'changed'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa78d02-7cac-4d1f-a51c-6c1e82f67b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id=\"../models/aya-101\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a009da-960b-4af0-aa4a-91283ceafcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function construct_prompt at 0x7f093bfc0ca0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "100%|██████████| 24845/24845 [00:02<00:00, 12388.82ex/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 13823.88ex/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 14223.77ex/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 12930.62ex/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 12807.04ex/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 13454.06ex/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 13613.45ex/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 12855.32ex/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 12796.88ex/s]\n"
     ]
    }
   ],
   "source": [
    "all_lang_data={\n",
    "    'english':'copa-en',\n",
    "    'croatian':'copa-hr',\n",
    "    'Slovenian':'copa-sl',\n",
    "    'Cerkno-dialect-of-Slovenian':'copa-sl-cer',\n",
    "    'Serbian':'copa-sr',\n",
    "    'Torlak-dialect':'copa-sr-tor',\n",
    "    'Macedonian':'copa-mk' ,\n",
    "    'Chakavian':'copa-ck' \n",
    "}\n",
    "prompt_template=\"\"\"Instruction: Given the premise, \"\"{premise}\"\", What is the most plausible {question}?\n",
    "    A: {choice1}\n",
    "    B: {choice2}\n",
    "    Plausible {question}:\"\"\"\n",
    "\n",
    "choices=[\"A\",\"B\"]\n",
    "\n",
    "def construct_prompt(row):\n",
    "    prompt=(prompt_template.format(**row, correct_answer=\"\")).strip()\n",
    "    return {'inputs':prompt,'labels':choices[row['label']]}\n",
    "    \n",
    "train_dataset_p=train_dataset.map(construct_prompt)\n",
    "val_dataset_p=val_dataset.map(construct_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8320940a-7246-4d55-b416-6a48f44d3366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?ba/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.61ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 65.27ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max target length: 2\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "import numpy as np\n",
    "# The maximum total input sequence length after tokenization.\n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "def tokenize_input(dataset):\n",
    "    tokenized_inputs = dataset.map(lambda x: tokenizer(x[\"inputs\"], truncation=True), batched=True, remove_columns=[\"inputs\", \"labels\"])\n",
    "    input_lenghts = [len(x) for x in tokenized_inputs[\"input_ids\"]]\n",
    "    # take 85 percentile of max length for better utilization\n",
    "    max_source_length = int(np.percentile(input_lenghts, 85))\n",
    "    print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "    # The maximum total sequence length for target text after tokenization.\n",
    "    # Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "    tokenized_targets = dataset.map(lambda x: tokenizer(x[\"labels\"], truncation=True), batched=True, remove_columns=[\"inputs\", \"labels\"])\n",
    "    target_lenghts = [len(x) for x in tokenized_targets[\"input_ids\"]]\n",
    "    # take 90 percentile of max length for better utilization\n",
    "    max_target_length = int(np.percentile(target_lenghts, 90))\n",
    "    print(f\"Max target length: {max_target_length}\")\n",
    "    return max_source_length,max_target_length\n",
    "    \n",
    "max_source_length,max_target_length=tokenize_input(train_dataset_p['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f373fc0-0281-4959-9e61-d500e0daaf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  8.46ba/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DatasetDict' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_inputs\n\u001b[1;32m     21\u001b[0m tokenized_dataset \u001b[38;5;241m=\u001b[39m train_dataset_p\u001b[38;5;241m.\u001b[39mmap(preprocess_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, remove_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpremise\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoice1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoice2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchanged\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeys of tokenized dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(tokenized_dataset\u001b[38;5;241m.\u001b[39mfeatures)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# save datasets to disk for later easy loading\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# tokenized_dataset.save_to_disk(\"data/train\")\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# tokenized_dataset[\"test\"].save_to_disk(\"data/eval\")\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetDict' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "def preprocess_function(sample,padding=\"max_length\"):\n",
    "    # add prefix to the input for t5\n",
    "    inputs = [item for item in sample[\"inputs\"]]\n",
    "\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(text_target=sample[\"labels\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = train_dataset_p.map(preprocess_function, batched=True, remove_columns=[\"premise\", \"choice1\",\"choice2\",\"question\",\"idx\",\"label\",\"changed\",\"inputs\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset.features)}\")\n",
    "\n",
    "# save datasets to disk for later easy loading\n",
    "# tokenized_dataset.save_to_disk(\"data/train\")\n",
    "# tokenized_dataset[\"test\"].save_to_disk(\"data/eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb6f73-7e46-49a2-ac1a-d0e59c6367c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "133b7636-62c1-47dc-9a22-0246ba12a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "tokenized_dataset=load_from_disk('data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be727a59-a8ed-4a94-bb0e-d8bf39b62b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 24845\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161e8b30-8a5a-47b0-8ed2-5aacf2984888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType\n",
    "\n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    " r=16,\n",
    " lora_alpha=32,\n",
    " target_modules=[\"q\", \"v\"],\n",
    " lora_dropout=0.05,\n",
    " bias=\"none\",\n",
    " task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bb962cc-6195-4ab4-b255-0f3c6dfbc416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.t5.modeling_t5 because of the following error (look up to see its traceback):\n[Errno 13] Permission denied: '/root/orc-open-ondemand/www-ood/ood/apps/sys/dashboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/transformers/utils/import_utils.py:1099\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:37\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     BaseModelOutput,\n\u001b[1;32m     32\u001b[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     Seq2SeqQuestionAnsweringModelOutput,\n\u001b[1;32m     36\u001b[0m )\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALL_LAYERNORM_LAYERS, find_pruneable_heads_and_indices, prune_linear_layer\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/transformers/modeling_utils.py:86\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch_model, infer_auto_device_map, init_empty_weights\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     88\u001b[0m         check_tied_parameters_on_same_device,\n\u001b[1;32m     89\u001b[0m         find_tied_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m         set_module_tensor_to_device,\n\u001b[1;32m     95\u001b[0m     )\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/accelerate/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.21.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     cpu_offload,\n\u001b[1;32m      6\u001b[0m     cpu_offload_with_hook,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/accelerate/accelerator.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader, skip_first_batches\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/accelerate/checkpointing.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradScaler\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     MODEL_NAME,\n\u001b[1;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[1;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[1;32m     28\u001b[0m     SCALER_NAME,\n\u001b[1;32m     29\u001b[0m     SCHEDULER_NAME,\n\u001b[1;32m     30\u001b[0m     get_pretty_name,\n\u001b[1;32m     31\u001b[0m     is_tpu_available,\n\u001b[1;32m     32\u001b[0m     is_xpu_available,\n\u001b[1;32m     33\u001b[0m     save,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tpu_available(check_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/accelerate/utils/__init__.py:131\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepspeed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    123\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[1;32m    124\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m         HfDeepSpeedConfig,\n\u001b[1;32m    129\u001b[0m     )\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbnb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m has_4bit_bnb_layers, load_and_quantize_model\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_fsdp_model, load_fsdp_optimizer, save_fsdp_model, save_fsdp_optimizer\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/accelerate/utils/bnb.py:42\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bnb_available():\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     MatmulLtState,\n\u001b[1;32m      9\u001b[0m     bmm_cublas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     matmul_4bit\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/research/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     switchback_bnb,\n\u001b[1;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[1;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/research/nn/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/research/nn/modules.py:8\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalOptimManager\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/optim/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madagrad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/cextension.py:13\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup\u001b[38;5;241m.\u001b[39minitialized \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[43msetup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cuda_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m lib \u001b[38;5;241m=\u001b[39m setup\u001b[38;5;241m.\u001b[39mlib\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:120\u001b[0m, in \u001b[0;36mCUDASetup.run_cuda_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda_setup_log \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 120\u001b[0m binary_name, cudart_path, cc, cuda_version_string \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_cuda_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcudart_path \u001b[38;5;241m=\u001b[39m cudart_path\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:337\u001b[0m, in \u001b[0;36mevaluate_cuda_setup\u001b[0;34m()\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibbitsandbytes_cpu.so\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m cudart_path \u001b[38;5;241m=\u001b[39m \u001b[43mdetermine_cuda_runtime_lib_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m ccs \u001b[38;5;241m=\u001b[39m get_compute_capabilities()\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:295\u001b[0m, in \u001b[0;36mdetermine_cuda_runtime_lib_path\u001b[0;34m()\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_var, value \u001b[38;5;129;01min\u001b[39;00m remaining_candidate_env_vars\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 295\u001b[0m     cuda_runtime_libs\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mfind_cuda_lib_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cuda_runtime_libs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:232\u001b[0m, in \u001b[0;36mfind_cuda_lib_in\u001b[0;34m(paths_list_candidate)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_cuda_lib_in\u001b[39m(paths_list_candidate: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Set[Path]:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_cuda_runtime_lib_paths(\n\u001b[0;32m--> 232\u001b[0m         \u001b[43mresolve_paths_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths_list_candidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     )\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:227\u001b[0m, in \u001b[0;36mresolve_paths_list\u001b[0;34m(paths_list_candidate)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03mSearches a given environmental var for the CUDA runtime library,\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03mi.e. `libcudart.so`.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mremove_non_existent_dirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_candidate_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths_list_candidate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:201\u001b[0m, in \u001b[0;36mremove_non_existent_dirs\u001b[0;34m(candidate_paths)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m errno\u001b[38;5;241m.\u001b[39mENAMETOOLONG:\n\u001b[0;32m--> 201\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mPermissionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m pex:\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:197\u001b[0m, in \u001b[0;36mremove_non_existent_dirs\u001b[0;34m(candidate_paths)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    198\u001b[0m         existent_directories\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[0;32m/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/pathlib.py:1424\u001b[0m, in \u001b[0;36mPath.exists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1424\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/pathlib.py:1232\u001b[0m, in \u001b[0;36mPath.stat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;124;03mReturn the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;124;03mos.stat() does.\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/root/orc-open-ondemand/www-ood/ood/apps/sys/dashboard'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/aya-101\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# load model from the hub\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:492\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    489\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 492\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    494\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    495\u001b[0m     )\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m )\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:376\u001b[0m, in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[0;32m--> 376\u001b[0m     supported_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:666\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping:\n\u001b[1;32m    665\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping[model_type]\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m model_types \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m key\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:680\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:625\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[0;32m--> 625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/transformers/utils/import_utils.py:1089\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1089\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect_copa/vnv/test/lib/python3.9/site-packages/transformers/utils/import_utils.py:1101\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.t5.modeling_t5 because of the following error (look up to see its traceback):\n[Errno 13] Permission denied: '/root/orc-open-ondemand/www-ood/ood/apps/sys/dashboard'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "# huggingface hub model id\n",
    "model_id = \"../models/aya-101\"\n",
    "\n",
    "# load model from the hub\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, load_in_8bit=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fadbe10-9bd0-4d4e-85ad-3cbf58ed4b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1ce6a-d3fe-4888-992f-0501a19e2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "output_dir=\"../output_models/lora\"\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "\tauto_find_batch_size=True,\n",
    "    learning_rate=1e-3, # higher learning rate\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"no\",\n",
    "    max_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bcff6-6789-428c-88f3-71c7c7001c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5729194d-3313-43e1-8aec-5aa21beb5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our LoRA model & tokenizer results\n",
    "peft_model_id=\"temp\"\n",
    "trainer.model.save_pretrained(peft_model_id)\n",
    "tokenizer.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d9ddbf-af1e-4edd-b666-65a4c0030209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftModel, PeftConfig\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSeq2SeqLM, AutoTokenizer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load peft config for pre-trained checkpoint etc.\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/peft/__init__.py:22\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.8.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     AutoPeftModel,\n\u001b[1;32m     24\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[1;32m     25\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[1;32m     26\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[1;32m     27\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[1;32m     28\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[1;32m     29\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[1;32m     33\u001b[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     inject_adapter_in_model,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftMixedModel\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/peft/auto.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_exists\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     AutoModel,\n\u001b[1;32m     25\u001b[0m     AutoModelForCausalLM,\n\u001b[1;32m     26\u001b[0m     AutoModelForQuestionAnswering,\n\u001b[1;32m     27\u001b[0m     AutoModelForSeq2SeqLM,\n\u001b[1;32m     28\u001b[0m     AutoModelForSequenceClassification,\n\u001b[1;32m     29\u001b[0m     AutoModelForTokenClassification,\n\u001b[1;32m     30\u001b[0m     AutoTokenizer,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1039\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/transformers/utils/import_utils.py:1272\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1272\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1273\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/transformers/utils/import_utils.py:1282\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1285\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1286\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1287\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/sw/spack/apps/linux-centos8-x86_64/gcc-9.3.0/python-3.8.6-ff/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/transformers/models/__init__.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     albert,\n\u001b[1;32m     17\u001b[0m     align,\n\u001b[1;32m     18\u001b[0m     altclip,\n\u001b[1;32m     19\u001b[0m     audio_spectrogram_transformer,\n\u001b[1;32m     20\u001b[0m     auto,\n\u001b[1;32m     21\u001b[0m     autoformer,\n\u001b[1;32m     22\u001b[0m     bark,\n\u001b[1;32m     23\u001b[0m     bart,\n\u001b[1;32m     24\u001b[0m     barthez,\n\u001b[1;32m     25\u001b[0m     bartpho,\n\u001b[1;32m     26\u001b[0m     beit,\n\u001b[1;32m     27\u001b[0m     bert,\n\u001b[1;32m     28\u001b[0m     bert_generation,\n\u001b[1;32m     29\u001b[0m     bert_japanese,\n\u001b[1;32m     30\u001b[0m     bertweet,\n\u001b[1;32m     31\u001b[0m     big_bird,\n\u001b[1;32m     32\u001b[0m     bigbird_pegasus,\n\u001b[1;32m     33\u001b[0m     biogpt,\n\u001b[1;32m     34\u001b[0m     bit,\n\u001b[1;32m     35\u001b[0m     blenderbot,\n\u001b[1;32m     36\u001b[0m     blenderbot_small,\n\u001b[1;32m     37\u001b[0m     blip,\n\u001b[1;32m     38\u001b[0m     blip_2,\n\u001b[1;32m     39\u001b[0m     bloom,\n\u001b[1;32m     40\u001b[0m     bridgetower,\n\u001b[1;32m     41\u001b[0m     bros,\n\u001b[1;32m     42\u001b[0m     byt5,\n\u001b[1;32m     43\u001b[0m     camembert,\n\u001b[1;32m     44\u001b[0m     canine,\n\u001b[1;32m     45\u001b[0m     chinese_clip,\n\u001b[1;32m     46\u001b[0m     clap,\n\u001b[1;32m     47\u001b[0m     clip,\n\u001b[1;32m     48\u001b[0m     clipseg,\n\u001b[1;32m     49\u001b[0m     code_llama,\n\u001b[1;32m     50\u001b[0m     codegen,\n\u001b[1;32m     51\u001b[0m     conditional_detr,\n\u001b[1;32m     52\u001b[0m     convbert,\n\u001b[1;32m     53\u001b[0m     convnext,\n\u001b[1;32m     54\u001b[0m     convnextv2,\n\u001b[1;32m     55\u001b[0m     cpm,\n\u001b[1;32m     56\u001b[0m     cpmant,\n\u001b[1;32m     57\u001b[0m     ctrl,\n\u001b[1;32m     58\u001b[0m     cvt,\n\u001b[1;32m     59\u001b[0m     data2vec,\n\u001b[1;32m     60\u001b[0m     deberta,\n\u001b[1;32m     61\u001b[0m     deberta_v2,\n\u001b[1;32m     62\u001b[0m     decision_transformer,\n\u001b[1;32m     63\u001b[0m     deformable_detr,\n\u001b[1;32m     64\u001b[0m     deit,\n\u001b[1;32m     65\u001b[0m     deprecated,\n\u001b[1;32m     66\u001b[0m     deta,\n\u001b[1;32m     67\u001b[0m     detr,\n\u001b[1;32m     68\u001b[0m     dialogpt,\n\u001b[1;32m     69\u001b[0m     dinat,\n\u001b[1;32m     70\u001b[0m     dinov2,\n\u001b[1;32m     71\u001b[0m     distilbert,\n\u001b[1;32m     72\u001b[0m     dit,\n\u001b[1;32m     73\u001b[0m     donut,\n\u001b[1;32m     74\u001b[0m     dpr,\n\u001b[1;32m     75\u001b[0m     dpt,\n\u001b[1;32m     76\u001b[0m     efficientformer,\n\u001b[1;32m     77\u001b[0m     efficientnet,\n\u001b[1;32m     78\u001b[0m     electra,\n\u001b[1;32m     79\u001b[0m     encodec,\n\u001b[1;32m     80\u001b[0m     encoder_decoder,\n\u001b[1;32m     81\u001b[0m     ernie,\n\u001b[1;32m     82\u001b[0m     ernie_m,\n\u001b[1;32m     83\u001b[0m     esm,\n\u001b[1;32m     84\u001b[0m     falcon,\n\u001b[1;32m     85\u001b[0m     flaubert,\n\u001b[1;32m     86\u001b[0m     flava,\n\u001b[1;32m     87\u001b[0m     fnet,\n\u001b[1;32m     88\u001b[0m     focalnet,\n\u001b[1;32m     89\u001b[0m     fsmt,\n\u001b[1;32m     90\u001b[0m     funnel,\n\u001b[1;32m     91\u001b[0m     git,\n\u001b[1;32m     92\u001b[0m     glpn,\n\u001b[1;32m     93\u001b[0m     gpt2,\n\u001b[1;32m     94\u001b[0m     gpt_bigcode,\n\u001b[1;32m     95\u001b[0m     gpt_neo,\n\u001b[1;32m     96\u001b[0m     gpt_neox,\n\u001b[1;32m     97\u001b[0m     gpt_neox_japanese,\n\u001b[1;32m     98\u001b[0m     gpt_sw3,\n\u001b[1;32m     99\u001b[0m     gptj,\n\u001b[1;32m    100\u001b[0m     gptsan_japanese,\n\u001b[1;32m    101\u001b[0m     graphormer,\n\u001b[1;32m    102\u001b[0m     groupvit,\n\u001b[1;32m    103\u001b[0m     herbert,\n\u001b[1;32m    104\u001b[0m     hubert,\n\u001b[1;32m    105\u001b[0m     ibert,\n\u001b[1;32m    106\u001b[0m     idefics,\n\u001b[1;32m    107\u001b[0m     imagegpt,\n\u001b[1;32m    108\u001b[0m     informer,\n\u001b[1;32m    109\u001b[0m     instructblip,\n\u001b[1;32m    110\u001b[0m     jukebox,\n\u001b[1;32m    111\u001b[0m     layoutlm,\n\u001b[1;32m    112\u001b[0m     layoutlmv2,\n\u001b[1;32m    113\u001b[0m     layoutlmv3,\n\u001b[1;32m    114\u001b[0m     layoutxlm,\n\u001b[1;32m    115\u001b[0m     led,\n\u001b[1;32m    116\u001b[0m     levit,\n\u001b[1;32m    117\u001b[0m     lilt,\n\u001b[1;32m    118\u001b[0m     llama,\n\u001b[1;32m    119\u001b[0m     longformer,\n\u001b[1;32m    120\u001b[0m     longt5,\n\u001b[1;32m    121\u001b[0m     luke,\n\u001b[1;32m    122\u001b[0m     lxmert,\n\u001b[1;32m    123\u001b[0m     m2m_100,\n\u001b[1;32m    124\u001b[0m     marian,\n\u001b[1;32m    125\u001b[0m     markuplm,\n\u001b[1;32m    126\u001b[0m     mask2former,\n\u001b[1;32m    127\u001b[0m     maskformer,\n\u001b[1;32m    128\u001b[0m     mbart,\n\u001b[1;32m    129\u001b[0m     mbart50,\n\u001b[1;32m    130\u001b[0m     mega,\n\u001b[1;32m    131\u001b[0m     megatron_bert,\n\u001b[1;32m    132\u001b[0m     megatron_gpt2,\n\u001b[1;32m    133\u001b[0m     mgp_str,\n\u001b[1;32m    134\u001b[0m     mistral,\n\u001b[1;32m    135\u001b[0m     mluke,\n\u001b[1;32m    136\u001b[0m     mobilebert,\n\u001b[1;32m    137\u001b[0m     mobilenet_v1,\n\u001b[1;32m    138\u001b[0m     mobilenet_v2,\n\u001b[1;32m    139\u001b[0m     mobilevit,\n\u001b[1;32m    140\u001b[0m     mobilevitv2,\n\u001b[1;32m    141\u001b[0m     mpnet,\n\u001b[1;32m    142\u001b[0m     mpt,\n\u001b[1;32m    143\u001b[0m     mra,\n\u001b[1;32m    144\u001b[0m     mt5,\n\u001b[1;32m    145\u001b[0m     musicgen,\n\u001b[1;32m    146\u001b[0m     mvp,\n\u001b[1;32m    147\u001b[0m     nat,\n\u001b[1;32m    148\u001b[0m     nezha,\n\u001b[1;32m    149\u001b[0m     nllb,\n\u001b[1;32m    150\u001b[0m     nllb_moe,\n\u001b[1;32m    151\u001b[0m     nougat,\n\u001b[1;32m    152\u001b[0m     nystromformer,\n\u001b[1;32m    153\u001b[0m     oneformer,\n\u001b[1;32m    154\u001b[0m     openai,\n\u001b[1;32m    155\u001b[0m     opt,\n\u001b[1;32m    156\u001b[0m     owlvit,\n\u001b[1;32m    157\u001b[0m     pegasus,\n\u001b[1;32m    158\u001b[0m     pegasus_x,\n\u001b[1;32m    159\u001b[0m     perceiver,\n\u001b[1;32m    160\u001b[0m     persimmon,\n\u001b[1;32m    161\u001b[0m     phobert,\n\u001b[1;32m    162\u001b[0m     pix2struct,\n\u001b[1;32m    163\u001b[0m     plbart,\n\u001b[1;32m    164\u001b[0m     poolformer,\n\u001b[1;32m    165\u001b[0m     pop2piano,\n\u001b[1;32m    166\u001b[0m     prophetnet,\n\u001b[1;32m    167\u001b[0m     pvt,\n\u001b[1;32m    168\u001b[0m     qdqbert,\n\u001b[1;32m    169\u001b[0m     rag,\n\u001b[1;32m    170\u001b[0m     realm,\n\u001b[1;32m    171\u001b[0m     reformer,\n\u001b[1;32m    172\u001b[0m     regnet,\n\u001b[1;32m    173\u001b[0m     rembert,\n\u001b[1;32m    174\u001b[0m     resnet,\n\u001b[1;32m    175\u001b[0m     roberta,\n\u001b[1;32m    176\u001b[0m     roberta_prelayernorm,\n\u001b[1;32m    177\u001b[0m     roc_bert,\n\u001b[1;32m    178\u001b[0m     roformer,\n\u001b[1;32m    179\u001b[0m     rwkv,\n\u001b[1;32m    180\u001b[0m     sam,\n\u001b[1;32m    181\u001b[0m     segformer,\n\u001b[1;32m    182\u001b[0m     sew,\n\u001b[1;32m    183\u001b[0m     sew_d,\n\u001b[1;32m    184\u001b[0m     speech_encoder_decoder,\n\u001b[1;32m    185\u001b[0m     speech_to_text,\n\u001b[1;32m    186\u001b[0m     speech_to_text_2,\n\u001b[1;32m    187\u001b[0m     speecht5,\n\u001b[1;32m    188\u001b[0m     splinter,\n\u001b[1;32m    189\u001b[0m     squeezebert,\n\u001b[1;32m    190\u001b[0m     swiftformer,\n\u001b[1;32m    191\u001b[0m     swin,\n\u001b[1;32m    192\u001b[0m     swin2sr,\n\u001b[1;32m    193\u001b[0m     swinv2,\n\u001b[1;32m    194\u001b[0m     switch_transformers,\n\u001b[1;32m    195\u001b[0m     t5,\n\u001b[1;32m    196\u001b[0m     table_transformer,\n\u001b[1;32m    197\u001b[0m     tapas,\n\u001b[1;32m    198\u001b[0m     time_series_transformer,\n\u001b[1;32m    199\u001b[0m     timesformer,\n\u001b[1;32m    200\u001b[0m     timm_backbone,\n\u001b[1;32m    201\u001b[0m     transfo_xl,\n\u001b[1;32m    202\u001b[0m     trocr,\n\u001b[1;32m    203\u001b[0m     tvlt,\n\u001b[1;32m    204\u001b[0m     umt5,\n\u001b[1;32m    205\u001b[0m     unispeech,\n\u001b[1;32m    206\u001b[0m     unispeech_sat,\n\u001b[1;32m    207\u001b[0m     upernet,\n\u001b[1;32m    208\u001b[0m     videomae,\n\u001b[1;32m    209\u001b[0m     vilt,\n\u001b[1;32m    210\u001b[0m     vision_encoder_decoder,\n\u001b[1;32m    211\u001b[0m     vision_text_dual_encoder,\n\u001b[1;32m    212\u001b[0m     visual_bert,\n\u001b[1;32m    213\u001b[0m     vit,\n\u001b[1;32m    214\u001b[0m     vit_hybrid,\n\u001b[1;32m    215\u001b[0m     vit_mae,\n\u001b[1;32m    216\u001b[0m     vit_msn,\n\u001b[1;32m    217\u001b[0m     vitdet,\n\u001b[1;32m    218\u001b[0m     vitmatte,\n\u001b[1;32m    219\u001b[0m     vits,\n\u001b[1;32m    220\u001b[0m     vivit,\n\u001b[1;32m    221\u001b[0m     wav2vec2,\n\u001b[1;32m    222\u001b[0m     wav2vec2_conformer,\n\u001b[1;32m    223\u001b[0m     wav2vec2_phoneme,\n\u001b[1;32m    224\u001b[0m     wav2vec2_with_lm,\n\u001b[1;32m    225\u001b[0m     wavlm,\n\u001b[1;32m    226\u001b[0m     whisper,\n\u001b[1;32m    227\u001b[0m     x_clip,\n\u001b[1;32m    228\u001b[0m     xglm,\n\u001b[1;32m    229\u001b[0m     xlm,\n\u001b[1;32m    230\u001b[0m     xlm_prophetnet,\n\u001b[1;32m    231\u001b[0m     xlm_roberta,\n\u001b[1;32m    232\u001b[0m     xlm_roberta_xl,\n\u001b[1;32m    233\u001b[0m     xlnet,\n\u001b[1;32m    234\u001b[0m     xmod,\n\u001b[1;32m    235\u001b[0m     yolos,\n\u001b[1;32m    236\u001b[0m     yoso,\n\u001b[1;32m    237\u001b[0m )\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:779\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:874\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:973\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load peft config for pre-trained checkpoint etc.\n",
    "peft_model_id = \"temp\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path,   device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0202a61d-a511-4c8c-b6a8-f07f37099c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8628d377-b15e-421f-a318-eeb1cbf52c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 11/11 [02:16<00:00, 12.44s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "097babb9-e95a-4c59-a0ce-b4d3b59ca149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "'CUDASetup' object has no attribute 'cuda_available'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ffaisal/dialect-copa/vnv/vnv_copa/lib/python3.8/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92f632-4729-463f-8566-3ba3b4ac7666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copa",
   "language": "python",
   "name": "copa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
